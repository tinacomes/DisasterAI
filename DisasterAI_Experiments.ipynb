{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DisasterAI Experimental Framework\n",
    "\n",
    "**Research Focus:** How AI alignment affects trust dynamics, filter bubbles, and information accuracy in disaster scenarios\n",
    "\n",
    "## Quick Start Guide\n",
    "1. Run Setup cells (Sections 1-2)\n",
    "2. Choose experiment type (Section 3)\n",
    "3. Analyze temporal visualizations (Section 4)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install mesa matplotlib numpy networkx -q\n",
    "\n",
    "# Mount Google Drive (for saving results)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    save_dir = \"/content/drive/MyDrive/DisasterAI_Results\"\n",
    "    print(\"✓ Running in Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    save_dir = \"./test_results\"\n",
    "    print(\"✓ Running locally\")\n",
    "\n",
    "import os\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"✓ Results will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Model Files\n",
    "\n",
    "**If running on Colab:** Upload `DisasterAI_Model.py` using the file upload button below.\n",
    "\n",
    "**If running locally:** Ensure `DisasterAI_Model.py` is in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model file if in Colab\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Please upload DisasterAI_Model.py:\")\n",
    "    uploaded = files.upload()\n",
    "    if 'DisasterAI_Model.py' in uploaded:\n",
    "        print(\"✓ Model file uploaded successfully\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: DisasterAI_Model.py not found. Please upload it.\")\n",
    "else:\n",
    "    if os.path.exists('DisasterAI_Model.py'):\n",
    "        print(\"✓ Model file found\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: DisasterAI_Model.py not found in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Model and Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DisasterAI_Model import DisasterModel, HumanAgent\n",
    "\n",
    "print(\"✓ Model imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Experimental Designs\n",
    "\n",
    "## Design Philosophy\n",
    "All experiments use **temporal visualizations** showing evolution over time, NOT final snapshots.\n",
    "\n",
    "Key metrics tracked over time:\n",
    "- **Q-values**: Learning trajectories for AI, human, and self-action modes\n",
    "- **Trust dynamics**: Evolution of trust in different sources\n",
    "- **SECI/AECI**: Filter bubble formation and AI reliance over time\n",
    "- **Belief accuracy**: How information quality changes throughout simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment A: Dual-Timeline Feedback Mechanism\n",
    "\n",
    "**Research Question:** Does the dual-timeline feedback (fast info quality + slow relief outcome) correctly guide agent learning?\n",
    "\n",
    "**Design:**\n",
    "- **Conditions:** High AI alignment (0.9) vs Low AI alignment (0.1)\n",
    "- **Duration:** 150 ticks\n",
    "- **Agent Mix:** 50% exploratory, 50% exploitative\n",
    "- **Key Hypothesis:** Exploratory agents should decrease Q(AI) with confirming AI due to faster info quality feedback\n",
    "\n",
    "**Temporal Metrics:**\n",
    "1. Q-value evolution for each source (A_0, human, self_action)\n",
    "2. Trust evolution in AI sources\n",
    "3. Feedback event timeline (when info vs relief feedback occurs)\n",
    "4. AI usage patterns over time\n",
    "\n",
    "**Expected Temporal Patterns:**\n",
    "- Info quality feedback: Occurs 3-5 ticks after query (fast)\n",
    "- Relief feedback: Occurs 15-25 ticks after action (slow)\n",
    "- Exploratory Q(AI): Should decline over time with confirming AI\n",
    "- Exploitative Q(AI): Changes more slowly, less sensitive to info feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment A: Dual-Timeline Feedback\n",
    "\n",
    "base_params = {\n",
    "    'share_exploitative': 0.5,\n",
    "    'share_of_disaster': 0.15,\n",
    "    'initial_trust': 0.3,\n",
    "    'initial_ai_trust': 0.25,\n",
    "    'number_of_humans': 100,\n",
    "    'share_confirming': 0.7,\n",
    "    'disaster_dynamics': 2,\n",
    "    'width': 30,\n",
    "    'height': 30,\n",
    "    'ticks': 150,\n",
    "    'learning_rate': 0.1,\n",
    "    'epsilon': 0.3,\n",
    "    'exploit_trust_lr': 0.015,\n",
    "    'explor_trust_lr': 0.03,\n",
    "}\n",
    "\n",
    "def run_dual_feedback_test(ai_alignment, test_name):\n",
    "    \"\"\"Run single test and collect TEMPORAL metrics.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {test_name}\")\n",
    "    print(f\"AI Alignment: {ai_alignment}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    params = base_params.copy()\n",
    "    params['ai_alignment_level'] = ai_alignment\n",
    "    model = DisasterModel(**params)\n",
    "\n",
    "    # Temporal tracking structures\n",
    "    q_values_by_tick = {'exploratory': {'A_0': [], 'human': [], 'self_action': []},\n",
    "                        'exploitative': {'A_0': [], 'human': [], 'self_action': []}}\n",
    "    trust_by_tick = {'exploratory': [], 'exploitative': []}\n",
    "    feedback_timeline = {'info': [], 'relief': []}\n",
    "    info_feedback_counts = {'exploratory': 0, 'exploitative': 0}\n",
    "    relief_feedback_counts = {'exploratory': 0, 'exploitative': 0}\n",
    "\n",
    "    # Select sample agents for tracking\n",
    "    sample_agents = {}\n",
    "    for agent in model.agent_list:\n",
    "        if isinstance(agent, HumanAgent):\n",
    "            if agent.agent_type == 'exploratory' and 'exploratory' not in sample_agents:\n",
    "                sample_agents['exploratory'] = agent\n",
    "            elif agent.agent_type == 'exploitative' and 'exploitative' not in sample_agents:\n",
    "                sample_agents['exploitative'] = agent\n",
    "        if len(sample_agents) == 2:\n",
    "            break\n",
    "\n",
    "    # Run simulation and collect TEMPORAL data\n",
    "    for tick in range(params['ticks']):\n",
    "        # Track BEFORE step\n",
    "        for agent_type in ['exploratory', 'exploitative']:\n",
    "            if agent_type in sample_agents:\n",
    "                agent = sample_agents[agent_type]\n",
    "                q_values_by_tick[agent_type]['A_0'].append(agent.q_table.get('A_0', 0.0))\n",
    "                q_values_by_tick[agent_type]['human'].append(agent.q_table.get('human', 0.0))\n",
    "                q_values_by_tick[agent_type]['self_action'].append(agent.q_table.get('self_action', 0.0))\n",
    "                trust_by_tick[agent_type].append(agent.trust.get('A_0', 0.5))\n",
    "\n",
    "                prev_info_pending = len(agent.pending_info_evaluations)\n",
    "                prev_relief_pending = len(agent.pending_rewards)\n",
    "\n",
    "        model.step()\n",
    "\n",
    "        # Track feedback events\n",
    "        for agent_type in ['exploratory', 'exploitative']:\n",
    "            if agent_type in sample_agents:\n",
    "                agent = sample_agents[agent_type]\n",
    "                current_info = len(agent.pending_info_evaluations)\n",
    "                current_relief = len(agent.pending_rewards)\n",
    "\n",
    "                if current_info < prev_info_pending:\n",
    "                    info_feedback_counts[agent_type] += (prev_info_pending - current_info)\n",
    "                    feedback_timeline['info'].append((tick, agent_type))\n",
    "\n",
    "                if current_relief < prev_relief_pending:\n",
    "                    relief_feedback_counts[agent_type] += (prev_relief_pending - current_relief)\n",
    "                    feedback_timeline['relief'].append((tick, agent_type))\n",
    "\n",
    "    return {\n",
    "        'q_values': q_values_by_tick,\n",
    "        'trust': trust_by_tick,\n",
    "        'info_counts': info_feedback_counts,\n",
    "        'relief_counts': relief_feedback_counts,\n",
    "        'feedback_timeline': feedback_timeline,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "def visualize_dual_feedback(results_high, results_low):\n",
    "    \"\"\"Create TEMPORAL visualization of dual-timeline feedback.\"\"\"\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # 1. Q-Values Evolution (High Alignment) - TEMPORAL\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    for source in ['A_0', 'human', 'self_action']:\n",
    "        for agent_type in ['exploratory', 'exploitative']:\n",
    "            data = results_high['q_values'][agent_type][source]\n",
    "            linestyle = '-' if agent_type == 'exploratory' else '--'\n",
    "            ax1.plot(data, linestyle=linestyle, label=f\"{agent_type[:6]}: {source}\", alpha=0.8)\n",
    "    ax1.set_title('Q-Values Over Time: High Alignment (0.9)\\nConfirming AI', fontsize=10, fontweight='bold')\n",
    "    ax1.set_xlabel('Tick (Time)')\n",
    "    ax1.set_ylabel('Q-Value')\n",
    "    ax1.legend(fontsize=7)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=0, color='k', linestyle=':', alpha=0.3)\n",
    "\n",
    "    # 2. Q-Values Evolution (Low Alignment) - TEMPORAL\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    for source in ['A_0', 'human', 'self_action']:\n",
    "        for agent_type in ['exploratory', 'exploitative']:\n",
    "            data = results_low['q_values'][agent_type][source]\n",
    "            linestyle = '-' if agent_type == 'exploratory' else '--'\n",
    "            ax2.plot(data, linestyle=linestyle, label=f\"{agent_type[:6]}: {source}\", alpha=0.8)\n",
    "    ax2.set_title('Q-Values Over Time: Low Alignment (0.1)\\nTruthful AI', fontsize=10, fontweight='bold')\n",
    "    ax2.set_xlabel('Tick (Time)')\n",
    "    ax2.set_ylabel('Q-Value')\n",
    "    ax2.legend(fontsize=7)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.axhline(y=0, color='k', linestyle=':', alpha=0.3)\n",
    "\n",
    "    # 3. Trust Evolution - TEMPORAL\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    ax3.plot(results_high['trust']['exploratory'], '-', label='Explor: High Align', color='blue', alpha=0.7)\n",
    "    ax3.plot(results_high['trust']['exploitative'], '--', label='Exploit: High Align', color='blue', alpha=0.7)\n",
    "    ax3.plot(results_low['trust']['exploratory'], '-', label='Explor: Low Align', color='green', alpha=0.7)\n",
    "    ax3.plot(results_low['trust']['exploitative'], '--', label='Exploit: Low Align', color='green', alpha=0.7)\n",
    "    ax3.set_title('Trust in AI Evolution Over Time', fontsize=10, fontweight='bold')\n",
    "    ax3.set_xlabel('Tick (Time)')\n",
    "    ax3.set_ylabel('Trust')\n",
    "    ax3.legend(fontsize=7)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4-5. Feedback Timeline - TEMPORAL (showing when events occur)\n",
    "    for idx, (results, title_suffix) in enumerate([(results_high, 'High Alignment'), (results_low, 'Low Alignment')]):\n",
    "        ax = plt.subplot(3, 3, 4 + idx)\n",
    "        info_explor = [t for t, at in results['feedback_timeline']['info'] if at == 'exploratory']\n",
    "        info_exploit = [t for t, at in results['feedback_timeline']['info'] if at == 'exploitative']\n",
    "        relief_explor = [t for t, at in results['feedback_timeline']['relief'] if at == 'exploratory']\n",
    "        relief_exploit = [t for t, at in results['feedback_timeline']['relief'] if at == 'exploitative']\n",
    "\n",
    "        if info_explor:\n",
    "            ax.scatter(info_explor, [1]*len(info_explor), marker='o', s=30, alpha=0.6, label='Info: Explor', color='blue')\n",
    "        if info_exploit:\n",
    "            ax.scatter(info_exploit, [0.8]*len(info_exploit), marker='s', s=30, alpha=0.6, label='Info: Exploit', color='lightblue')\n",
    "        if relief_explor:\n",
    "            ax.scatter(relief_explor, [0.4]*len(relief_explor), marker='^', s=30, alpha=0.6, label='Relief: Explor', color='red')\n",
    "        if relief_exploit:\n",
    "            ax.scatter(relief_exploit, [0.2]*len(relief_exploit), marker='v', s=30, alpha=0.6, label='Relief: Exploit', color='pink')\n",
    "\n",
    "        ax.set_title(f'Feedback Timeline Over Time\\n{title_suffix}', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Tick (Time)')\n",
    "        ax.set_yticks([0.2, 0.4, 0.8, 1.0])\n",
    "        ax.set_yticklabels(['Relief\\nExploit', 'Relief\\nExplor', 'Info\\nExploit', 'Info\\nExplor'], fontsize=7)\n",
    "        ax.legend(fontsize=7, loc='upper right')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.set_ylim(0, 1.2)\n",
    "\n",
    "    # 6. Feedback Frequency Comparison\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    categories = ['Explor\\nInfo', 'Explor\\nRelief', 'Exploit\\nInfo', 'Exploit\\nRelief']\n",
    "    high_align = [\n",
    "        results_high['info_counts']['exploratory'],\n",
    "        results_high['relief_counts']['exploratory'],\n",
    "        results_high['info_counts']['exploitative'],\n",
    "        results_high['relief_counts']['exploitative']\n",
    "    ]\n",
    "    low_align = [\n",
    "        results_low['info_counts']['exploratory'],\n",
    "        results_low['relief_counts']['exploratory'],\n",
    "        results_low['info_counts']['exploitative'],\n",
    "        results_low['relief_counts']['exploitative']\n",
    "    ]\n",
    "\n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    ax6.bar(x - width/2, high_align, width, label='High Align (0.9)', alpha=0.8, color='orange')\n",
    "    ax6.bar(x + width/2, low_align, width, label='Low Align (0.1)', alpha=0.8, color='green')\n",
    "    ax6.set_title('Total Feedback Events', fontsize=10, fontweight='bold')\n",
    "    ax6.set_ylabel('Event Count')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(categories, fontsize=8)\n",
    "    ax6.legend(fontsize=8)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # 7-8. Final Q-Value Snapshots (for comparison)\n",
    "    for idx, (results, title_suffix) in enumerate([(results_high, 'High Alignment'), (results_low, 'Low Alignment')]):\n",
    "        ax = plt.subplot(3, 3, 7 + idx)\n",
    "        sources = ['A_0', 'human', 'self']\n",
    "        explor = [\n",
    "            results['q_values']['exploratory']['A_0'][-1],\n",
    "            results['q_values']['exploratory']['human'][-1],\n",
    "            results['q_values']['exploratory']['self_action'][-1]\n",
    "        ]\n",
    "        exploit = [\n",
    "            results['q_values']['exploitative']['A_0'][-1],\n",
    "            results['q_values']['exploitative']['human'][-1],\n",
    "            results['q_values']['exploitative']['self_action'][-1]\n",
    "        ]\n",
    "\n",
    "        x = np.arange(len(sources))\n",
    "        width = 0.35\n",
    "        ax.bar(x - width/2, explor, width, label='Exploratory', alpha=0.8, color='blue')\n",
    "        ax.bar(x + width/2, exploit, width, label='Exploitative', alpha=0.8, color='red')\n",
    "        ax.set_title(f'Final Q-Values\\n{title_suffix}', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Q-Value')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(sources, fontsize=8)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.axhline(y=0, color='k', linestyle=':', alpha=0.3)\n",
    "\n",
    "    # 9. Summary\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    ax9.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "DUAL-TIMELINE FEEDBACK TEST\n",
    "TEMPORAL ANALYSIS SUMMARY\n",
    "\n",
    "High Alignment (0.9) - Confirming AI:\n",
    "├─ Exploratory: Info={results_high['info_counts']['exploratory']}, Relief={results_high['relief_counts']['exploratory']}\n",
    "├─ Exploitative: Info={results_high['info_counts']['exploitative']}, Relief={results_high['relief_counts']['exploitative']}\n",
    "\n",
    "Low Alignment (0.1) - Truthful AI:\n",
    "├─ Exploratory: Info={results_low['info_counts']['exploratory']}, Relief={results_low['relief_counts']['exploratory']}\n",
    "├─ Exploitative: Info={results_low['info_counts']['exploitative']}, Relief={results_low['relief_counts']['exploitative']}\n",
    "\n",
    "TEMPORAL PATTERNS OBSERVED:\n",
    "• Info feedback: Fast (3-5 tick delay)\n",
    "• Relief feedback: Slow (15-25 tick delay)\n",
    "• Q-values evolve differently over time\n",
    "• Exploratory agents more responsive\n",
    "    \"\"\"\n",
    "    ax9.text(0.1, 0.5, summary_text, fontsize=9, family='monospace',\n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(save_dir, 'experiment_A_dual_feedback.png')\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Visualization saved to: {output_path}\")\n",
    "    return fig\n",
    "\n",
    "print(\"✓ Experiment A functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment B: Filter Bubble Dynamics\n",
    "\n",
    "**Research Questions:**\n",
    "1. Does AI alignment CREATE filter bubbles where none existed?\n",
    "2. Does AI alignment AMPLIFY existing social filter bubbles?\n",
    "3. Can truthful AI BREAK filter bubbles?\n",
    "\n",
    "**Design:**\n",
    "- **Conditions:** Control (no AI), Truthful (0.1), Mixed (0.5), Confirming (0.9)\n",
    "- **Duration:** 200 ticks\n",
    "- **Network:** 3 tight communities (pre-existing social structure)\n",
    "\n",
    "**Temporal Metrics:**\n",
    "1. **SECI (Social Echo Chamber Index)** over time: -1 (strong echo chamber) to +1 (diverse)\n",
    "2. **AECI (AI Echo Chamber Index)** over time: 0 (human-only) to 1 (AI-only)\n",
    "3. Belief accuracy evolution (MAE from ground truth)\n",
    "4. AI usage rate over time\n",
    "\n",
    "**Hypotheses:**\n",
    "- H1: Confirming AI amplifies filter bubbles (SECI becomes more negative over time)\n",
    "- H2: Truthful AI breaks filter bubbles (SECI increases toward 0 over time)\n",
    "- H3: High AECI + confirming AI creates strongest bubbles\n",
    "- H4: Exploratory agents show weaker filter bubble effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment B: Filter Bubble Dynamics\n",
    "\n",
    "filter_params = {\n",
    "    'share_exploitative': 0.5,\n",
    "    'share_of_disaster': 0.15,\n",
    "    'initial_trust': 0.3,\n",
    "    'initial_ai_trust': 0.25,\n",
    "    'number_of_humans': 100,\n",
    "    'share_confirming': 0.7,\n",
    "    'disaster_dynamics': 2,\n",
    "    'width': 30,\n",
    "    'height': 30,\n",
    "    'ticks': 200,\n",
    "    'learning_rate': 0.1,\n",
    "    'epsilon': 0.3,\n",
    "    'exploit_trust_lr': 0.015,\n",
    "    'explor_trust_lr': 0.03,\n",
    "}\n",
    "\n",
    "def run_filter_bubble_experiment(ai_alignment, test_name):\n",
    "    \"\"\"Run filter bubble condition and track TEMPORAL metrics.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Running: {test_name}\")\n",
    "    print(f\"AI Alignment: {ai_alignment if ai_alignment is not None else 'None (Control)'}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    params = filter_params.copy()\n",
    "    if ai_alignment is not None:\n",
    "        params['ai_alignment_level'] = ai_alignment\n",
    "    else:\n",
    "        params['ai_alignment_level'] = 0.5\n",
    "\n",
    "    model = DisasterModel(**params)\n",
    "\n",
    "    if ai_alignment is None:\n",
    "        model.num_ai = 0\n",
    "        model.ai_list = []\n",
    "        print(\"Control: AI agents removed\\n\")\n",
    "\n",
    "    # Temporal tracking\n",
    "    seci_by_tick = {'exploit': [], 'explor': [], 'combined': []}\n",
    "    aeci_by_tick = {'exploit': [], 'explor': [], 'combined': []}\n",
    "    belief_accuracy = {'exploit': [], 'explor': []}\n",
    "    ai_usage_rate = {'exploit': [], 'explor': []}\n",
    "\n",
    "    # Run simulation\n",
    "    for tick in range(params['ticks']):\n",
    "        model.step()\n",
    "\n",
    "        # Extract SECI temporal data\n",
    "        if model.seci_data and len(model.seci_data) > 0:\n",
    "            latest_seci = model.seci_data[-1]\n",
    "            seci_by_tick['exploit'].append(latest_seci[1])\n",
    "            seci_by_tick['explor'].append(latest_seci[2])\n",
    "            seci_by_tick['combined'].append((latest_seci[1] + latest_seci[2]) / 2)\n",
    "\n",
    "        # Extract AECI temporal data\n",
    "        if model.aeci_data and len(model.aeci_data) > 0:\n",
    "            latest_aeci = model.aeci_data[-1]\n",
    "            aeci_by_tick['exploit'].append(latest_aeci[1])\n",
    "            aeci_by_tick['explor'].append(latest_aeci[2])\n",
    "            aeci_by_tick['combined'].append((latest_aeci[1] + latest_aeci[2]) / 2)\n",
    "\n",
    "        # Belief accuracy every 10 ticks\n",
    "        if tick % 10 == 0:\n",
    "            exploit_errors = []\n",
    "            explor_errors = []\n",
    "\n",
    "            for agent in model.agent_list:\n",
    "                if isinstance(agent, HumanAgent):\n",
    "                    mae = 0\n",
    "                    count = 0\n",
    "                    for cell, belief_info in agent.beliefs.items():\n",
    "                        if isinstance(belief_info, dict):\n",
    "                            belief_level = belief_info.get('level', 0)\n",
    "                            true_level = model.disaster_grid[cell]\n",
    "                            mae += abs(belief_level - true_level)\n",
    "                            count += 1\n",
    "\n",
    "                    if count > 0:\n",
    "                        mae /= count\n",
    "                        if agent.agent_type == \"exploitative\":\n",
    "                            exploit_errors.append(mae)\n",
    "                        else:\n",
    "                            explor_errors.append(mae)\n",
    "\n",
    "            belief_accuracy['exploit'].append(np.mean(exploit_errors) if exploit_errors else 0)\n",
    "            belief_accuracy['explor'].append(np.mean(explor_errors) if explor_errors else 0)\n",
    "\n",
    "        # AI usage rate every 10 ticks\n",
    "        if tick % 10 == 0:\n",
    "            exploit_ai_calls = []\n",
    "            explor_ai_calls = []\n",
    "\n",
    "            for agent in model.agent_list:\n",
    "                if isinstance(agent, HumanAgent):\n",
    "                    if hasattr(agent, 'accum_calls_ai') and hasattr(agent, 'accum_calls_total'):\n",
    "                        if agent.accum_calls_total > 0:\n",
    "                            rate = agent.accum_calls_ai / agent.accum_calls_total\n",
    "                            if agent.agent_type == \"exploitative\":\n",
    "                                exploit_ai_calls.append(rate)\n",
    "                            else:\n",
    "                                explor_ai_calls.append(rate)\n",
    "\n",
    "            ai_usage_rate['exploit'].append(np.mean(exploit_ai_calls) if exploit_ai_calls else 0)\n",
    "            ai_usage_rate['explor'].append(np.mean(explor_ai_calls) if explor_ai_calls else 0)\n",
    "\n",
    "    print(f\"\\nFinal Metrics:\")\n",
    "    print(f\"  SECI (Exploit): {seci_by_tick['exploit'][-1]:.3f}\")\n",
    "    print(f\"  SECI (Explor):  {seci_by_tick['explor'][-1]:.3f}\")\n",
    "    if aeci_by_tick['exploit']:\n",
    "        print(f\"  AECI (Exploit): {aeci_by_tick['exploit'][-1]:.3f}\")\n",
    "        print(f\"  AECI (Explor):  {aeci_by_tick['explor'][-1]:.3f}\")\n",
    "\n",
    "    return {\n",
    "        'seci': seci_by_tick,\n",
    "        'aeci': aeci_by_tick,\n",
    "        'belief_accuracy': belief_accuracy,\n",
    "        'ai_usage': ai_usage_rate,\n",
    "        'model': model,\n",
    "        'params': params\n",
    "    }\n",
    "\n",
    "def visualize_filter_bubbles(results_dict):\n",
    "    \"\"\"Create TEMPORAL visualization of filter bubble evolution.\"\"\"\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "\n",
    "    conditions = list(results_dict.keys())\n",
    "    colors = {'Control': 'gray', 'Truthful (0.1)': 'green',\n",
    "              'Mixed (0.5)': 'orange', 'Confirming (0.9)': 'red'}\n",
    "\n",
    "    # 1. SECI Evolution - Exploitative (TEMPORAL)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    for cond in conditions:\n",
    "        data = results_dict[cond]['seci']['exploit']\n",
    "        ax1.plot(data, label=cond, color=colors.get(cond, 'blue'), linewidth=2, alpha=0.8)\n",
    "    ax1.axhline(y=0, color='k', linestyle=':', alpha=0.5, label='No Echo Chamber')\n",
    "    ax1.axhline(y=-0.5, color='r', linestyle='--', alpha=0.3, label='Strong Echo')\n",
    "    ax1.set_title('SECI Evolution Over Time: Exploitative\\n(More negative = Stronger filter bubble)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax1.set_xlabel('Tick (Time)')\n",
    "    ax1.set_ylabel('SECI (-1 to +1)')\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. SECI Evolution - Exploratory (TEMPORAL)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    for cond in conditions:\n",
    "        data = results_dict[cond]['seci']['explor']\n",
    "        ax2.plot(data, label=cond, color=colors.get(cond, 'blue'), linewidth=2, alpha=0.8)\n",
    "    ax2.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "    ax2.axhline(y=-0.5, color='r', linestyle='--', alpha=0.3)\n",
    "    ax2.set_title('SECI Evolution Over Time: Exploratory\\n(More negative = Stronger filter bubble)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax2.set_xlabel('Tick (Time)')\n",
    "    ax2.set_ylabel('SECI (-1 to +1)')\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3. AECI Evolution (TEMPORAL)\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    for cond in conditions:\n",
    "        if cond != 'Control':\n",
    "            data_exploit = results_dict[cond]['aeci']['exploit']\n",
    "            data_explor = results_dict[cond]['aeci']['explor']\n",
    "            ax3.plot(data_exploit, linestyle='--', label=f'{cond} (Exploit)',\n",
    "                    color=colors.get(cond, 'blue'), linewidth=1.5, alpha=0.7)\n",
    "            ax3.plot(data_explor, linestyle='-', label=f'{cond} (Explor)',\n",
    "                    color=colors.get(cond, 'blue'), linewidth=1.5, alpha=0.7)\n",
    "    ax3.set_title('AECI Evolution Over Time\\n(Higher = More AI reliance)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax3.set_xlabel('Tick (Time)')\n",
    "    ax3.set_ylabel('AECI (0 to 1)')\n",
    "    ax3.legend(fontsize=7)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Belief Accuracy Evolution (TEMPORAL)\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    for cond in conditions:\n",
    "        data_exploit = results_dict[cond]['belief_accuracy']['exploit']\n",
    "        data_explor = results_dict[cond]['belief_accuracy']['explor']\n",
    "        ticks = list(range(0, len(data_exploit) * 10, 10))\n",
    "        ax4.plot(ticks, data_exploit, linestyle='--', label=f'{cond} (Exploit)',\n",
    "                color=colors.get(cond, 'blue'), linewidth=1.5, alpha=0.7)\n",
    "        ax4.plot(ticks, data_explor, linestyle='-', label=f'{cond} (Explor)',\n",
    "                color=colors.get(cond, 'blue'), linewidth=1.5, alpha=0.7)\n",
    "    ax4.set_title('Belief Accuracy Over Time (MAE)\\n(Lower = More accurate)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax4.set_xlabel('Tick (Time)')\n",
    "    ax4.set_ylabel('Mean Absolute Error')\n",
    "    ax4.legend(fontsize=7)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    # 5. SECI Change from Baseline (TEMPORAL)\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    for cond in conditions:\n",
    "        seci_exploit = results_dict[cond]['seci']['exploit']\n",
    "        if len(seci_exploit) > 10:\n",
    "            initial_seci = np.mean(seci_exploit[0:10])\n",
    "            delta_seci = [val - initial_seci for val in seci_exploit]\n",
    "            ax5.plot(delta_seci, label=f'{cond} (Exploit)',\n",
    "                    color=colors.get(cond, 'blue'), linewidth=2, alpha=0.8)\n",
    "    ax5.axhline(y=0, color='k', linestyle=':', alpha=0.5, label='No change')\n",
    "    ax5.set_title('SECI Change Over Time: Exploitative\\n(Negative = Increasing echo chamber)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax5.set_xlabel('Tick (Time)')\n",
    "    ax5.set_ylabel('Δ SECI from baseline')\n",
    "    ax5.legend(fontsize=8)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "    # 6. Final SECI Comparison\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    x_pos = np.arange(len(conditions))\n",
    "    exploit_final_seci = [results_dict[cond]['seci']['exploit'][-1] for cond in conditions]\n",
    "    explor_final_seci = [results_dict[cond]['seci']['explor'][-1] for cond in conditions]\n",
    "\n",
    "    width = 0.35\n",
    "    ax6.bar(x_pos - width/2, exploit_final_seci, width, label='Exploitative', alpha=0.8, color='red')\n",
    "    ax6.bar(x_pos + width/2, explor_final_seci, width, label='Exploratory', alpha=0.8, color='blue')\n",
    "    ax6.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "    ax6.set_title('Final SECI Values\\n(Lower = Stronger filter bubbles)',\n",
    "                  fontsize=10, fontweight='bold')\n",
    "    ax6.set_ylabel('SECI (-1 to +1)')\n",
    "    ax6.set_xticks(x_pos)\n",
    "    ax6.set_xticklabels(conditions, rotation=15, ha='right', fontsize=8)\n",
    "    ax6.legend(fontsize=8)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # 7-9. Summary and Hypothesis Testing\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    ax7.axis('off')\n",
    "\n",
    "    control_final = results_dict['Control']['seci']['exploit'][-1]\n",
    "    confirming_final = results_dict['Confirming (0.9)']['seci']['exploit'][-1]\n",
    "    truthful_final = results_dict['Truthful (0.1)']['seci']['exploit'][-1]\n",
    "\n",
    "    h1 = \"SUPPORTED\" if confirming_final < control_final else \"REJECTED\"\n",
    "    h2 = \"SUPPORTED\" if truthful_final > control_final else \"REJECTED\"\n",
    "\n",
    "    summary = f\"\"\"\n",
    "FILTER BUBBLE EXPERIMENT\n",
    "TEMPORAL ANALYSIS SUMMARY\n",
    "\n",
    "Hypothesis Testing:\n",
    "\n",
    "H1 (Confirming amplifies): {h1}\n",
    "  Control: {control_final:.3f}\n",
    "  Confirming: {confirming_final:.3f}\n",
    "\n",
    "H2 (Truthful breaks): {h2}\n",
    "  Truthful: {truthful_final:.3f}\n",
    "\n",
    "KEY TEMPORAL PATTERNS:\n",
    "• SECI tracked over 200 ticks\n",
    "• Filter bubbles evolve over time\n",
    "• Different trajectories per condition\n",
    "• Metrics are temporal, not snapshots\n",
    "    \"\"\"\n",
    "    ax7.text(0.05, 0.95, summary, fontsize=9, family='monospace',\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(save_dir, 'experiment_B_filter_bubbles.png')\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Visualization saved to: {output_path}\")\n",
    "    return fig\n",
    "\n",
    "print(\"✓ Experiment B functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Experiments\n",
    "\n",
    "Choose which experiment to run below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment A: Dual-Timeline Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT A: DUAL-TIMELINE FEEDBACK\")\n",
    "print(\"Testing temporal learning patterns\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run both conditions\n",
    "results_high = run_dual_feedback_test(ai_alignment=0.9, test_name=\"High Alignment (Confirming)\")\n",
    "results_low = run_dual_feedback_test(ai_alignment=0.1, test_name=\"Low Alignment (Truthful)\")\n",
    "\n",
    "# Visualize temporal results\n",
    "print(\"\\nGenerating temporal visualizations...\")\n",
    "fig = visualize_dual_feedback(results_high, results_low)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT A COMPLETE\")\n",
    "print(\"All visualizations show TEMPORAL evolution (not snapshots)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment B: Filter Bubble Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT B: FILTER BUBBLE DYNAMICS\")\n",
    "print(\"Testing temporal filter bubble evolution\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define conditions\n",
    "conditions = {\n",
    "    'Control': None,\n",
    "    'Truthful (0.1)': 0.1,\n",
    "    'Mixed (0.5)': 0.5,\n",
    "    'Confirming (0.9)': 0.9\n",
    "}\n",
    "\n",
    "# Run all conditions\n",
    "results = {}\n",
    "for name, alignment in conditions.items():\n",
    "    results[name] = run_filter_bubble_experiment(alignment, name)\n",
    "\n",
    "# Visualize temporal results\n",
    "print(\"\\nGenerating temporal visualizations...\")\n",
    "fig = visualize_filter_bubbles(results)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT B COMPLETE\")\n",
    "print(\"All visualizations show TEMPORAL evolution (not snapshots)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verification: Temporal vs Snapshot Analysis\n",
    "\n",
    "This section confirms that all visualizations are **temporal** (showing evolution over time) rather than final snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEMPORAL VISUALIZATION VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "verification_points = [\n",
    "    \"✓ Q-values plotted as time series (tick-by-tick evolution)\",\n",
    "    \"✓ Trust evolution tracked continuously over simulation\",\n",
    "    \"✓ SECI/AECI measured at every tick (not just final state)\",\n",
    "    \"✓ Feedback timeline shows when events occur (temporal scatter)\",\n",
    "    \"✓ Belief accuracy sampled periodically (every 10 ticks)\",\n",
    "    \"✓ SECI change from baseline shows trajectory over time\",\n",
    "    \"✓ All line plots use tick (time) as x-axis\",\n",
    "    \"✓ Bar charts only used for final comparisons (minority of plots)\"\n",
    "]\n",
    "\n",
    "print(\"\\nVisualization Design Principles:\")\n",
    "for point in verification_points:\n",
    "    print(point)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIRMATION: All primary visualizations are TEMPORAL\")\n",
    "print(\"They show evolution over time, not just final snapshots\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experimental Design Summary\n",
    "\n",
    "### Temporal Measurement Philosophy\n",
    "\n",
    "This experimental framework prioritizes **temporal dynamics** over static endpoints:\n",
    "\n",
    "1. **Continuous Tracking**: Metrics captured at every simulation tick\n",
    "2. **Evolution Visualization**: Line plots show how phenomena develop\n",
    "3. **Event Timelines**: Scatter plots reveal when critical events occur\n",
    "4. **Trajectory Analysis**: Compare paths, not just destinations\n",
    "\n",
    "### Why Temporal > Snapshot?\n",
    "\n",
    "- **Learning Dynamics**: Q-values don't just converge—their path reveals learning mechanisms\n",
    "- **Trust Building**: Trust evolution shows how relationships develop\n",
    "- **Filter Bubble Formation**: SECI trajectory reveals amplification vs. breaking\n",
    "- **Dual Timelines**: Fast vs. slow feedback only visible through temporal analysis\n",
    "\n",
    "### Data Integrity\n",
    "\n",
    "All temporal data is:\n",
    "- ✓ Collected tick-by-tick during simulation\n",
    "- ✓ Stored in time-indexed arrays\n",
    "- ✓ Visualized with explicit time axes\n",
    "- ✓ Available for post-analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Run experiments on Colab\n",
    "2. Analyze temporal patterns in results\n",
    "3. Compare learning trajectories across conditions\n",
    "4. Identify critical time windows for interventions\n",
    "5. Export time-series data for statistical analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
